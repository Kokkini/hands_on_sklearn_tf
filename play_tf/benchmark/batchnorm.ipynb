{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbenchmark test for algorithms' efficiency\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "benchmark test for algorithms' efficiency\n",
    "'''\n",
    "# fixed random state\n",
    "# 95% accuracy\n",
    "# test accuracy increase\n",
    "# test training time\n",
    "# no learning rate tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
    "from tensorflow.contrib.layers import dropout\n",
    "from datetime import datetime\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variables that doesn't need to be updated every run\n",
    "np_seed = 4\n",
    "tf_seed = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables that need to be changed\n",
    "method = \"batchnorm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) (60000,) (10000,)\n",
      "-0.470742984694\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD0CAYAAABjJGgUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqQSKiCiVQBERpRIoIqLU/wPjyi3nYqyVbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e6e23d80f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare data\n",
    "np.random.seed(np_seed)\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "train_size = 60000\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data/256-0.5, mnist.target.astype(int), train_size=train_size,shuffle=True)\n",
    "m,n = X_train.shape\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# make sure things go well\n",
    "print(np.mean(X_train[40]))\n",
    "plt.matshow(X_train[40].reshape([28,28]))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(X,y,batch_size):\n",
    "    random_indice = np.random.permutation(X.shape[0])[:batch_size]\n",
    "    return [X[random_indice], y[random_indice]]\n",
    "def get_lr(lr_start,epoch):\n",
    "    return lr_start/(2**(epoch/300.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "test loss : 0.9879 test accuracy : 0.7967\n",
      "train loss: 0.9721 train accuracy: 0.8020\n",
      "elapsed time: 7 lr: 1.0e-01\n",
      "Time to log: 1.6504669189453125\n",
      "Epoch: 10\n",
      "test loss : 0.1595 test accuracy : 0.9555\n",
      "train loss: 0.1295 train accuracy: 0.9661\n",
      "elapsed time: 51 lr: 9.8e-02\n",
      "Time to log: 1.330540657043457\n",
      "Epoch: 20\n",
      "test loss : 0.1207 test accuracy : 0.9661\n",
      "train loss: 0.0783 train accuracy: 0.9804\n",
      "elapsed time: 93 lr: 9.5e-02\n",
      "Time to log: 1.470914363861084\n",
      "Epoch: 30\n",
      "test loss : 0.1090 test accuracy : 0.9683\n",
      "train loss: 0.0553 train accuracy: 0.9871\n",
      "elapsed time: 133 lr: 9.3e-02\n",
      "Time to log: 1.1721196174621582\n",
      "Epoch: 40\n",
      "test loss : 0.1044 test accuracy : 0.9698\n",
      "train loss: 0.0409 train accuracy: 0.9913\n",
      "elapsed time: 172 lr: 9.1e-02\n",
      "Time to log: 1.158583641052246\n",
      "Epoch: 50\n",
      "test loss : 0.1021 test accuracy : 0.9698\n",
      "train loss: 0.0319 train accuracy: 0.9943\n",
      "elapsed time: 210 lr: 8.9e-02\n",
      "Time to log: 1.115565538406372\n",
      "Epoch: 60\n",
      "test loss : 0.1021 test accuracy : 0.9697\n",
      "train loss: 0.0247 train accuracy: 0.9964\n",
      "elapsed time: 248 lr: 8.7e-02\n",
      "Time to log: 1.1891655921936035\n",
      "Epoch: 70\n",
      "test loss : 0.1015 test accuracy : 0.9706\n",
      "train loss: 0.0200 train accuracy: 0.9978\n",
      "elapsed time: 285 lr: 8.5e-02\n",
      "Time to log: 1.0397675037384033\n",
      "Epoch: 80\n",
      "test loss : 0.1033 test accuracy : 0.9689\n",
      "train loss: 0.0172 train accuracy: 0.9987\n",
      "elapsed time: 322 lr: 8.3e-02\n",
      "Time to log: 1.1104629039764404\n",
      "Epoch: 90\n",
      "test loss : 0.1036 test accuracy : 0.9698\n",
      "train loss: 0.0141 train accuracy: 0.9990\n",
      "elapsed time: 359 lr: 8.1e-02\n",
      "Time to log: 1.0397670269012451\n",
      "Epoch: 100\n",
      "test loss : 0.1055 test accuracy : 0.9705\n",
      "train loss: 0.0124 train accuracy: 0.9994\n",
      "elapsed time: 379 lr: 7.9e-02\n",
      "Time to log: 0.5263268947601318\n",
      "Epoch: 110\n",
      "test loss : 0.1065 test accuracy : 0.9708\n",
      "train loss: 0.0105 train accuracy: 0.9997\n",
      "elapsed time: 399 lr: 7.8e-02\n",
      "Time to log: 0.5801615715026855\n",
      "Epoch: 120\n",
      "test loss : 0.1064 test accuracy : 0.9703\n",
      "train loss: 0.0092 train accuracy: 0.9998\n",
      "elapsed time: 418 lr: 7.6e-02\n",
      "Time to log: 0.5299508571624756\n",
      "Epoch: 130\n",
      "test loss : 0.1076 test accuracy : 0.9710\n",
      "train loss: 0.0081 train accuracy: 0.9999\n",
      "elapsed time: 437 lr: 7.4e-02\n",
      "Time to log: 0.5188100337982178\n",
      "Epoch: 140\n",
      "test loss : 0.1087 test accuracy : 0.9708\n",
      "train loss: 0.0074 train accuracy: 0.9999\n",
      "elapsed time: 456 lr: 7.2e-02\n",
      "Time to log: 0.5227172374725342\n",
      "Epoch: 150\n",
      "test loss : 0.1095 test accuracy : 0.9702\n",
      "train loss: 0.0067 train accuracy: 1.0000\n",
      "elapsed time: 475 lr: 7.1e-02\n",
      "Time to log: 0.5184972286224365\n",
      "Epoch: 160\n",
      "test loss : 0.1091 test accuracy : 0.9707\n",
      "train loss: 0.0061 train accuracy: 0.9999\n",
      "elapsed time: 494 lr: 6.9e-02\n",
      "Time to log: 0.5252926349639893\n",
      "Epoch: 170\n",
      "test loss : 0.1103 test accuracy : 0.9703\n",
      "train loss: 0.0055 train accuracy: 1.0000\n",
      "elapsed time: 513 lr: 6.8e-02\n",
      "Time to log: 0.5727756023406982\n",
      "Epoch: 180\n",
      "test loss : 0.1110 test accuracy : 0.9709\n",
      "train loss: 0.0052 train accuracy: 1.0000\n",
      "elapsed time: 532 lr: 6.6e-02\n",
      "Time to log: 0.5272958278656006\n",
      "Epoch: 190\n",
      "test loss : 0.1125 test accuracy : 0.9704\n",
      "train loss: 0.0048 train accuracy: 1.0000\n",
      "elapsed time: 551 lr: 6.4e-02\n",
      "Time to log: 0.5255379676818848\n",
      "Epoch: 200\n",
      "test loss : 0.1119 test accuracy : 0.9711\n",
      "train loss: 0.0044 train accuracy: 1.0000\n",
      "elapsed time: 570 lr: 6.3e-02\n",
      "Time to log: 0.5200281143188477\n",
      "Epoch: 210\n",
      "test loss : 0.1126 test accuracy : 0.9710\n",
      "train loss: 0.0042 train accuracy: 1.0000\n",
      "elapsed time: 589 lr: 6.2e-02\n",
      "Time to log: 0.5218391418457031\n",
      "Epoch: 220\n",
      "test loss : 0.1132 test accuracy : 0.9715\n",
      "train loss: 0.0039 train accuracy: 1.0000\n",
      "elapsed time: 608 lr: 6.0e-02\n",
      "Time to log: 0.502922773361206\n",
      "Epoch: 230\n",
      "test loss : 0.1138 test accuracy : 0.9710\n",
      "train loss: 0.0037 train accuracy: 1.0000\n",
      "elapsed time: 626 lr: 5.9e-02\n",
      "Time to log: 0.500931978225708\n",
      "Epoch: 240\n",
      "test loss : 0.1147 test accuracy : 0.9706\n",
      "train loss: 0.0035 train accuracy: 1.0000\n",
      "elapsed time: 645 lr: 5.7e-02\n",
      "Time to log: 0.5013840198516846\n",
      "Epoch: 250\n",
      "test loss : 0.1145 test accuracy : 0.9708\n",
      "train loss: 0.0034 train accuracy: 1.0000\n",
      "elapsed time: 664 lr: 5.6e-02\n",
      "Time to log: 0.5145950317382812\n",
      "Epoch: 260\n",
      "test loss : 0.1149 test accuracy : 0.9716\n",
      "train loss: 0.0032 train accuracy: 1.0000\n",
      "elapsed time: 683 lr: 5.5e-02\n",
      "Time to log: 0.5243837833404541\n",
      "Epoch: 270\n",
      "test loss : 0.1150 test accuracy : 0.9714\n",
      "train loss: 0.0031 train accuracy: 1.0000\n",
      "elapsed time: 701 lr: 5.4e-02\n",
      "Time to log: 0.5026135444641113\n",
      "Epoch: 280\n",
      "test loss : 0.1160 test accuracy : 0.9706\n",
      "train loss: 0.0029 train accuracy: 1.0000\n",
      "elapsed time: 720 lr: 5.2e-02\n",
      "Time to log: 0.506101131439209\n",
      "Epoch: 290\n",
      "test loss : 0.1162 test accuracy : 0.9716\n",
      "train loss: 0.0029 train accuracy: 1.0000\n",
      "elapsed time: 738 lr: 5.1e-02\n",
      "Time to log: 0.5028972625732422\n",
      "Test accuracy : 0.971\n",
      "Train accuracy: 1.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e1280cd50af8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1103\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1105\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \"\"\"\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' %\n\u001b[1;32m--> 231\u001b[1;33m                       (fetch, type(fetch)))\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument None has invalid type <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# construction phase\n",
    "now = datetime.utcnow().strftime(\"%y%m%d-%H%M\")\n",
    "root_logdir = \"logs\"\n",
    "logdir_train = \"{}/{}_{}_train\".format(root_logdir, method, now)\n",
    "logdir_test = \"{}/{}_{}_test\".format(root_logdir,method,now)\n",
    "root_savedir = \"checkpoints\"\n",
    "savedir = \"{}/{}_{}\".format(root_savedir, method, now)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(tf_seed) # set random seed\n",
    "n_neurons = 50\n",
    "lr_start = 0.1\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.int64, shape=[None])\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name=\"is_training\")\n",
    "\n",
    "bn_params = {\n",
    "'is_training': is_training,\n",
    "'decay': 0.99,\n",
    "'updates_collections': None\n",
    "}\n",
    "\n",
    "with tf.variable_scope(\"forward\"):\n",
    "    dense_1 = fully_connected(X, 64, scope=\"dense_1\",normalizer_fn=batch_norm,normalizer_params=bn_params)\n",
    "    dense_2 = fully_connected(dense_1, 32, scope=\"dense_2\",normalizer_fn=batch_norm,normalizer_params=bn_params)\n",
    "    output = fully_connected(dense_2, 10, activation_fn=None, scope=\"output\")\n",
    "    \n",
    "with tf.variable_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y,name=\"xentropy\")\n",
    "    loss = tf.reduce_mean(xentropy,name=\"loss\")\n",
    "    \n",
    "with tf.variable_scope(\"annealing\"):\n",
    "    lr = tf.placeholder(tf.float32, shape=(), name=\"learning_rate\")\n",
    "    \n",
    "with tf.variable_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.variable_scope(\"eval\"):\n",
    "    pred = tf.argmax(output,axis=1,name=\"prediction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y),tf.float64))\n",
    "with tf.variable_scope(\"save\"):\n",
    "    saver = tf.train.Saver()\n",
    "    loss_summary = tf.summary.scalar(\"loss\", loss)\n",
    "    accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    summary = tf.summary.merge_all()\n",
    "    writer_test = tf.summary.FileWriter(logdir_test,tf.get_default_graph())\n",
    "    writer_train = tf.summary.FileWriter(logdir_train,tf.get_default_graph())\n",
    "# execution phase\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(np_seed) # set random seed\n",
    "    start_running = time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_epochs = 300\n",
    "    batch_size = 1000\n",
    "    n_batches = int(np.ceil(m/batch_size))\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        lr_ = get_lr(lr_start,epoch)\n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch,y:y_batch,lr:lr_,is_training:True})\n",
    "        if epoch%10==0:\n",
    "            start_time = time()\n",
    "            summary_test, loss_test,  accuracy_test  = sess.run([summary,loss,accuracy],feed_dict={X:X_test,y:y_test,is_training:False})\n",
    "            writer_test.add_summary(summary_test,epoch)\n",
    "            summary_train,loss_train,  accuracy_train  = sess.run([summary,loss,accuracy],feed_dict={X:X_train,y:y_train,is_training:False})\n",
    "            writer_train.add_summary(summary_train,epoch)\n",
    "            \n",
    "            print(\"Epoch:\",epoch)\n",
    "            print(\"test loss : %.4f\" % loss_test , \"test accuracy : %.4f\" % accuracy_test)\n",
    "            print(\"train loss: %.4f\" % loss_train, \"train accuracy: %.4f\" % accuracy_train)\n",
    "            print(\"elapsed time: %.0f\" % (time()-start_running), \"lr: %.1e\" % lr_)\n",
    "            print(\"Time to log:\",time()-start_time)\n",
    "        if epoch%50==0:\n",
    "            saver.save(sess,savedir+\"/model.ckpt\")\n",
    "    saver.save(sess,savedir+\"/model_final.ckpt\")\n",
    "    train_accuracy = sess.run(accuracy, feed_dict={X:X_train, y:y_train,is_training:False})\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X:X_test, y:y_test,is_training:False})\n",
    "    print(\"Test accuracy :\", test_accuracy)\n",
    "    print(\"Train accuracy:\", train_accuracy)\n",
    "    sess.run(writer_test.close())\n",
    "    sess.run(writer_train.close())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
