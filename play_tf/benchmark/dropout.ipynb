{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbenchmark test for algorithms' efficiency\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "benchmark test for algorithms' efficiency\n",
    "'''\n",
    "# fixed random state\n",
    "# 95% accuracy\n",
    "# test accuracy increase\n",
    "# test training time\n",
    "# no learning rate tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.contrib.layers import dropout\n",
    "from datetime import datetime\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variables that doesn't need to be updated every run\n",
    "np_seed = 4\n",
    "tf_seed = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables that need to be changed\n",
    "method = \"dropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) (60000,) (10000,)\n",
      "-0.470742984694\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD0CAYAAABjJGgUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqQSKiCiVQBERpRIoIqLU/wPjyi3nYqyVbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d363e0ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare data\n",
    "np.random.seed(np_seed)\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "train_size = 60000\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data/256-0.5, mnist.target.astype(int), train_size=train_size,shuffle=True)\n",
    "m,n = X_train.shape\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# make sure things go well\n",
    "print(np.mean(X_train[40]))\n",
    "plt.matshow(X_train[40].reshape([28,28]))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(X,y,batch_size):\n",
    "    random_indice = np.random.permutation(X.shape[0])[:batch_size]\n",
    "    return [X[random_indice], y[random_indice]]\n",
    "def get_lr(lr_start,epoch):\n",
    "    return lr_start/(2**(epoch/300.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "test loss : 1.1032 test accuracy : 0.6812\n",
      "train loss: 1.0896 train accuracy: 0.6919\n",
      "elapsed time: 5 lr: 1.0e-01\n",
      "Time to log: 0.6848545074462891\n",
      "Epoch: 10\n",
      "test loss : 0.3116 test accuracy : 0.9072\n",
      "train loss: 0.3024 train accuracy: 0.9123\n",
      "elapsed time: 52 lr: 9.8e-02\n",
      "Time to log: 0.7028725147247314\n",
      "Epoch: 20\n",
      "test loss : 0.2497 test accuracy : 0.9268\n",
      "train loss: 0.2404 train accuracy: 0.9293\n",
      "elapsed time: 95 lr: 9.5e-02\n",
      "Time to log: 0.6407053470611572\n",
      "Epoch: 30\n",
      "test loss : 0.2150 test accuracy : 0.9372\n",
      "train loss: 0.2038 train accuracy: 0.9410\n",
      "elapsed time: 139 lr: 9.3e-02\n",
      "Time to log: 0.8046410083770752\n",
      "Epoch: 40\n",
      "test loss : 0.1939 test accuracy : 0.9429\n",
      "train loss: 0.1810 train accuracy: 0.9470\n",
      "elapsed time: 186 lr: 9.1e-02\n",
      "Time to log: 0.8658039569854736\n",
      "Epoch: 50\n",
      "test loss : 0.1745 test accuracy : 0.9470\n",
      "train loss: 0.1626 train accuracy: 0.9525\n",
      "elapsed time: 231 lr: 8.9e-02\n",
      "Time to log: 0.6356918811798096\n",
      "Epoch: 60\n",
      "test loss : 0.1644 test accuracy : 0.9500\n",
      "train loss: 0.1510 train accuracy: 0.9552\n",
      "elapsed time: 276 lr: 8.7e-02\n",
      "Time to log: 0.7239382266998291\n",
      "Epoch: 70\n",
      "test loss : 0.1568 test accuracy : 0.9526\n",
      "train loss: 0.1420 train accuracy: 0.9585\n",
      "elapsed time: 317 lr: 8.5e-02\n",
      "Time to log: 0.6251654624938965\n",
      "Epoch: 80\n",
      "test loss : 0.1528 test accuracy : 0.9550\n",
      "train loss: 0.1361 train accuracy: 0.9603\n",
      "elapsed time: 359 lr: 8.3e-02\n",
      "Time to log: 0.6427104473114014\n",
      "Epoch: 90\n",
      "test loss : 0.1465 test accuracy : 0.9557\n",
      "train loss: 0.1299 train accuracy: 0.9612\n",
      "elapsed time: 406 lr: 8.1e-02\n",
      "Time to log: 0.6853301525115967\n",
      "Epoch: 100\n",
      "test loss : 0.1419 test accuracy : 0.9573\n",
      "train loss: 0.1239 train accuracy: 0.9631\n",
      "elapsed time: 451 lr: 7.9e-02\n",
      "Time to log: 0.7540082931518555\n",
      "Epoch: 110\n",
      "test loss : 0.1380 test accuracy : 0.9591\n",
      "train loss: 0.1191 train accuracy: 0.9646\n",
      "elapsed time: 497 lr: 7.8e-02\n",
      "Time to log: 0.866807222366333\n",
      "Epoch: 120\n",
      "test loss : 0.1377 test accuracy : 0.9598\n",
      "train loss: 0.1181 train accuracy: 0.9650\n",
      "elapsed time: 543 lr: 7.6e-02\n",
      "Time to log: 0.7329893112182617\n",
      "Epoch: 130\n",
      "test loss : 0.1350 test accuracy : 0.9601\n",
      "train loss: 0.1139 train accuracy: 0.9660\n",
      "elapsed time: 585 lr: 7.4e-02\n",
      "Time to log: 0.6903448104858398\n",
      "Epoch: 140\n",
      "test loss : 0.1305 test accuracy : 0.9613\n",
      "train loss: 0.1098 train accuracy: 0.9676\n",
      "elapsed time: 629 lr: 7.2e-02\n",
      "Time to log: 0.7986249923706055\n",
      "Epoch: 150\n",
      "test loss : 0.1324 test accuracy : 0.9610\n",
      "train loss: 0.1092 train accuracy: 0.9677\n",
      "elapsed time: 672 lr: 7.1e-02\n",
      "Time to log: 0.6231594085693359\n",
      "Epoch: 160\n",
      "test loss : 0.1278 test accuracy : 0.9623\n",
      "train loss: 0.1052 train accuracy: 0.9690\n",
      "elapsed time: 714 lr: 6.9e-02\n",
      "Time to log: 0.7164058685302734\n",
      "Epoch: 170\n",
      "test loss : 0.1259 test accuracy : 0.9623\n",
      "train loss: 0.1031 train accuracy: 0.9698\n",
      "elapsed time: 761 lr: 6.8e-02\n",
      "Time to log: 0.7570149898529053\n",
      "Epoch: 180\n",
      "test loss : 0.1245 test accuracy : 0.9629\n",
      "train loss: 0.1009 train accuracy: 0.9703\n",
      "elapsed time: 815 lr: 6.6e-02\n",
      "Time to log: 0.8241941928863525\n",
      "Epoch: 190\n",
      "test loss : 0.1236 test accuracy : 0.9636\n",
      "train loss: 0.0992 train accuracy: 0.9707\n",
      "elapsed time: 867 lr: 6.4e-02\n",
      "Time to log: 0.7249298095703125\n",
      "Epoch: 200\n",
      "test loss : 0.1228 test accuracy : 0.9642\n",
      "train loss: 0.0978 train accuracy: 0.9710\n",
      "elapsed time: 915 lr: 6.3e-02\n",
      "Time to log: 0.7133994102478027\n",
      "Epoch: 210\n",
      "test loss : 0.1220 test accuracy : 0.9643\n",
      "train loss: 0.0962 train accuracy: 0.9715\n",
      "elapsed time: 969 lr: 6.2e-02\n",
      "Time to log: 0.7830853462219238\n",
      "Epoch: 220\n",
      "test loss : 0.1216 test accuracy : 0.9648\n",
      "train loss: 0.0950 train accuracy: 0.9718\n",
      "elapsed time: 1021 lr: 6.0e-02\n",
      "Time to log: 0.6993610858917236\n",
      "Epoch: 230\n",
      "test loss : 0.1206 test accuracy : 0.9657\n",
      "train loss: 0.0933 train accuracy: 0.9723\n",
      "elapsed time: 1068 lr: 5.9e-02\n",
      "Time to log: 0.710399866104126\n",
      "Epoch: 240\n",
      "test loss : 0.1194 test accuracy : 0.9657\n",
      "train loss: 0.0926 train accuracy: 0.9725\n",
      "elapsed time: 1113 lr: 5.7e-02\n",
      "Time to log: 0.6326851844787598\n",
      "Epoch: 250\n",
      "test loss : 0.1178 test accuracy : 0.9660\n",
      "train loss: 0.0907 train accuracy: 0.9733\n",
      "elapsed time: 1176 lr: 5.6e-02\n",
      "Time to log: 1.3596177101135254\n",
      "Epoch: 260\n",
      "test loss : 0.1189 test accuracy : 0.9648\n",
      "train loss: 0.0907 train accuracy: 0.9729\n",
      "elapsed time: 1251 lr: 5.5e-02\n",
      "Time to log: 1.1951820850372314\n",
      "Epoch: 270\n",
      "test loss : 0.1151 test accuracy : 0.9661\n",
      "train loss: 0.0885 train accuracy: 0.9740\n",
      "elapsed time: 1318 lr: 5.4e-02\n",
      "Time to log: 1.2062220573425293\n",
      "Epoch: 280\n",
      "test loss : 0.1160 test accuracy : 0.9664\n",
      "train loss: 0.0877 train accuracy: 0.9740\n",
      "elapsed time: 1381 lr: 5.2e-02\n",
      "Time to log: 1.0307426452636719\n",
      "Epoch: 290\n",
      "test loss : 0.1148 test accuracy : 0.9662\n",
      "train loss: 0.0874 train accuracy: 0.9741\n",
      "elapsed time: 1441 lr: 5.1e-02\n",
      "Time to log: 1.2232563495635986\n",
      "Test accuracy : 0.9666\n",
      "Train accuracy: 0.974666666667\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-35099ae485b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1103\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1105\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \"\"\"\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' %\n\u001b[1;32m--> 231\u001b[1;33m                       (fetch, type(fetch)))\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument None has invalid type <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# construction phase\n",
    "now = datetime.utcnow().strftime(\"%y%m%d-%H%M\")\n",
    "root_logdir = \"logs\"\n",
    "logdir_train = \"{}/{}_{}_train\".format(root_logdir, method, now)\n",
    "logdir_test = \"{}/{}_{}_test\".format(root_logdir,method,now)\n",
    "root_savedir = \"checkpoints\"\n",
    "savedir = \"{}/{}_{}\".format(root_savedir, method, now)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(tf_seed) # set random seed\n",
    "n_neurons = 50\n",
    "lr_start = 0.1\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=[None, 784])\n",
    "y = tf.placeholder(tf.int64, shape=[None])\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name=\"is_training\")\n",
    "keep_prob = 0.75\n",
    "\n",
    "with tf.variable_scope(\"forward\"):\n",
    "    X_drop = dropout(X,keep_prob,is_training=is_training)\n",
    "    dense_1 = fully_connected(X_drop, 64, scope=\"dense_1\")\n",
    "    dense_1_drop = dropout(dense_1,keep_prob,is_training=is_training)\n",
    "    dense_2 = fully_connected(dense_1_drop, 32, scope=\"dense_2\")\n",
    "    dense_2_drop = dropout(dense_2,keep_prob,is_training=is_training)\n",
    "    output = fully_connected(dense_2_drop, 10, activation_fn=None, scope=\"output\")\n",
    "    \n",
    "with tf.variable_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y,name=\"xentropy\")\n",
    "    loss = tf.reduce_mean(xentropy,name=\"loss\")\n",
    "    \n",
    "with tf.variable_scope(\"annealing\"):\n",
    "    lr = tf.placeholder(tf.float32, shape=(), name=\"learning_rate\")\n",
    "    \n",
    "with tf.variable_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.variable_scope(\"eval\"):\n",
    "    pred = tf.argmax(output,axis=1,name=\"prediction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y),tf.float64))\n",
    "with tf.variable_scope(\"save\"):\n",
    "    saver = tf.train.Saver()\n",
    "    loss_summary = tf.summary.scalar(\"loss\", loss)\n",
    "    accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    summary = tf.summary.merge_all()\n",
    "    writer_test = tf.summary.FileWriter(logdir_test,tf.get_default_graph())\n",
    "    writer_train = tf.summary.FileWriter(logdir_train,tf.get_default_graph())\n",
    "# execution phase\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(np_seed) # set random seed\n",
    "    start_running = time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_epochs = 300\n",
    "    batch_size = 1000\n",
    "    n_batches = int(np.ceil(m/batch_size))\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        lr_ = get_lr(lr_start,epoch)\n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch,y:y_batch,lr:lr_,is_training:True})\n",
    "        if epoch%10==0:\n",
    "            start_time = time()\n",
    "            summary_test, loss_test,  accuracy_test  = sess.run([summary,loss,accuracy],feed_dict={X:X_test,y:y_test,is_training:False})\n",
    "            writer_test.add_summary(summary_test,epoch)\n",
    "            summary_train,loss_train,  accuracy_train  = sess.run([summary,loss,accuracy],feed_dict={X:X_train,y:y_train,is_training:False})\n",
    "            writer_train.add_summary(summary_train,epoch)\n",
    "            \n",
    "            print(\"Epoch:\",epoch)\n",
    "            print(\"test loss : %.4f\" % loss_test , \"test accuracy : %.4f\" % accuracy_test)\n",
    "            print(\"train loss: %.4f\" % loss_train, \"train accuracy: %.4f\" % accuracy_train)\n",
    "            print(\"elapsed time: %.0f\" % (time()-start_running), \"lr: %.1e\" % lr_)\n",
    "            print(\"Time to log:\",time()-start_time)\n",
    "        if epoch%50==0:\n",
    "            saver.save(sess,savedir+\"/model.ckpt\")\n",
    "    saver.save(sess,savedir+\"/model_final.ckpt\")\n",
    "    train_accuracy = np.mean(sess.run(pred, feed_dict={X:X_train, y:y_train,is_training:False})==y_train)\n",
    "    test_accuracy = np.mean(sess.run(pred, feed_dict={X:X_test, y:y_test,is_training:False})==y_test)\n",
    "    print(\"Test accuracy :\", test_accuracy)\n",
    "    print(\"Train accuracy:\", train_accuracy)\n",
    "    sess.run(writer_test.close())\n",
    "    sess.run(writer_train.close())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
