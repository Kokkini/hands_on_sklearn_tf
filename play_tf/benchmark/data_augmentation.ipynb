{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbenchmark test for algorithms' efficiency\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "benchmark test for algorithms' efficiency\n",
    "'''\n",
    "# fixed random state\n",
    "# 95% accuracy\n",
    "# test accuracy increase\n",
    "# test training time\n",
    "# no learning rate tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage.transform import rotate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from datetime import datetime\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variables that doesn't need to be updated every run\n",
    "np_seed = 4\n",
    "tf_seed = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables that need to be changed\n",
    "method = \"dataAug\"\n",
    "size_multiple = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD3CAYAAAAdUOFNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef626c5d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.219477862508\n",
      "(180000, 784) (180000,)\n",
      "0.130524498159\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "np.random.seed(np_seed)\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "train_size = 60000\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data/256, mnist.target.astype(int), train_size=train_size,shuffle=True)\n",
    "\n",
    "# augment data\n",
    "def augment_data(X_train,y_train): # I made a function so that temp memory will be free after the function terminates\n",
    "    rotation_angle = 10\n",
    "    rotate_left = []\n",
    "    rotate_right = []\n",
    "    for i in range(train_size):\n",
    "        img = X_train[i].reshape([28,28])\n",
    "        rotate_left.append(rotate(img,rotation_angle).reshape(784))\n",
    "        rotate_right.append(rotate(img,-rotation_angle).reshape(784))\n",
    "        if(i%5000==0): print(i)\n",
    "\n",
    "    rotate_left = np.asarray(rotate_left)\n",
    "    rotate_right = np.asarray(rotate_right)\n",
    "    \n",
    "    X_train=np.concatenate([X_train,rotate_left,rotate_right])\n",
    "    y_train=np.concatenate([y_train,y_train,y_train])\n",
    "    return [X_train,y_train]\n",
    "    \n",
    "\n",
    "X_train, y_train = augment_data(X_train,y_train)\n",
    "\n",
    "# make sure things go well\n",
    "plt.matshow(X_train[70000].reshape([28,28]))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(np.mean(X_train[70000]))\n",
    "\n",
    "# shuffle\n",
    "random_indice = np.random.permutation(size_multiple*train_size)\n",
    "X_train, y_train = X_train[random_indice], y_train[random_indice]\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(np.mean(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(X,y,batch_size):\n",
    "    random_indice = np.random.permutation(X.shape[0])[:batch_size]\n",
    "    return [X[random_indice], y[random_indice]]\n",
    "def get_lr(lr_start,epoch):\n",
    "    return lr_start/(2**(epoch/100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "test loss : 0.3550 test accuracy : 0.8959\n",
      "train loss: 0.4002 train accuracy: 0.8864\n",
      "elapsed time: 10 lr: 1.0e-01\n",
      "Time to log: 2.1703670024871826\n",
      "Epoch: 10\n",
      "test loss : 0.1371 test accuracy : 0.9597\n",
      "train loss: 0.1435 train accuracy: 0.9580\n",
      "elapsed time: 86 lr: 9.3e-02\n",
      "Time to log: 1.830366849899292\n",
      "Epoch: 20\n",
      "test loss : 0.1036 test accuracy : 0.9698\n",
      "train loss: 0.0952 train accuracy: 0.9718\n",
      "elapsed time: 159 lr: 8.7e-02\n",
      "Time to log: 1.7205755710601807\n",
      "Epoch: 30\n",
      "test loss : 0.0941 test accuracy : 0.9726\n",
      "train loss: 0.0746 train accuracy: 0.9777\n",
      "elapsed time: 233 lr: 8.1e-02\n",
      "Time to log: 1.7486495971679688\n",
      "Epoch: 40\n",
      "test loss : 0.0882 test accuracy : 0.9748\n",
      "train loss: 0.0618 train accuracy: 0.9814\n",
      "elapsed time: 308 lr: 7.6e-02\n",
      "Time to log: 1.7050330638885498\n",
      "Epoch: 50\n",
      "test loss : 0.0853 test accuracy : 0.9758\n",
      "train loss: 0.0533 train accuracy: 0.9838\n",
      "elapsed time: 381 lr: 7.1e-02\n",
      "Time to log: 1.8388898372650146\n",
      "Epoch: 60\n",
      "test loss : 0.0860 test accuracy : 0.9751\n",
      "train loss: 0.0484 train accuracy: 0.9852\n",
      "elapsed time: 461 lr: 6.6e-02\n",
      "Time to log: 1.8012890815734863\n",
      "Epoch: 70\n",
      "test loss : 0.0846 test accuracy : 0.9757\n",
      "train loss: 0.0437 train accuracy: 0.9869\n",
      "elapsed time: 535 lr: 6.2e-02\n",
      "Time to log: 2.1508610248565674\n",
      "Epoch: 80\n",
      "test loss : 0.0853 test accuracy : 0.9758\n",
      "train loss: 0.0401 train accuracy: 0.9883\n",
      "elapsed time: 608 lr: 5.7e-02\n",
      "Time to log: 1.6914968490600586\n",
      "Epoch: 90\n",
      "test loss : 0.0850 test accuracy : 0.9758\n",
      "train loss: 0.0373 train accuracy: 0.9891\n",
      "elapsed time: 682 lr: 5.4e-02\n",
      "Time to log: 1.6724622249603271\n",
      "Epoch: 100\n",
      "test loss : 0.0852 test accuracy : 0.9754\n",
      "train loss: 0.0348 train accuracy: 0.9900\n",
      "elapsed time: 754 lr: 5.0e-02\n",
      "Time to log: 1.6443724632263184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1aebabd2e24f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlr_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# construction phase\n",
    "now = datetime.utcnow().strftime(\"%y%m%d-%H%M\")\n",
    "root_logdir = \"logs\"\n",
    "logdir_train = \"{}/{}_{}_train\".format(root_logdir, method, now)\n",
    "logdir_test = \"{}/{}_{}_test\".format(root_logdir,method,now)\n",
    "root_savedir = \"checkpoints\"\n",
    "savedir = \"{}/base-{}\".format(root_savedir, now)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(tf_seed) # set random seed\n",
    "n_neurons = 50\n",
    "lr_start = 0.1\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=[None, 784])\n",
    "y = tf.placeholder(tf.int64, shape=[None])\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name=\"is_training\")\n",
    "keep_prob = 0.75\n",
    "\n",
    "with tf.variable_scope(\"forward\"):\n",
    "    dense_1 = fully_connected(X, 64, scope=\"dense_1\")\n",
    "    dense_2 = fully_connected(dense_1, 32, scope=\"dense_2\")\n",
    "    output = fully_connected(dense_2, 10, activation_fn=None, scope=\"output\")\n",
    "    \n",
    "with tf.variable_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y,name=\"xentropy\")\n",
    "    loss = tf.reduce_mean(xentropy,name=\"loss\")\n",
    "    \n",
    "with tf.variable_scope(\"annealing\"):\n",
    "    lr = tf.placeholder(tf.float32, shape=(), name=\"learning_rate\")\n",
    "    \n",
    "with tf.variable_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.variable_scope(\"eval\"):\n",
    "    pred = tf.argmax(output,axis=1,name=\"prediction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y),tf.float64))\n",
    "with tf.variable_scope(\"save\"):\n",
    "    saver = tf.train.Saver()\n",
    "    loss_summary = tf.summary.scalar(\"loss\", loss)\n",
    "    accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    summary = tf.summary.merge_all()\n",
    "    writer_test = tf.summary.FileWriter(logdir_test,tf.get_default_graph())\n",
    "    writer_train = tf.summary.FileWriter(logdir_train,tf.get_default_graph())\n",
    "# execution phase\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(np_seed) # set random seed\n",
    "    start_running = time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_epochs = 100\n",
    "    batch_size = 1000\n",
    "    n_batches = int(np.ceil(X_train.shape[0]/batch_size))\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        lr_ = get_lr(lr_start,epoch)\n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch,y:y_batch,lr:lr_,is_training:True})\n",
    "        if epoch%10==0:\n",
    "            start_time = time()\n",
    "            summary_test, loss_test,  accuracy_test  = sess.run([summary,loss,accuracy],feed_dict={X:X_test,y:y_test,is_training:False})\n",
    "            writer_test.add_summary(summary_test,epoch*size_multiple)\n",
    "            summary_train,loss_train,  accuracy_train  = sess.run([summary,loss,accuracy],feed_dict={X:X_train,y:y_train,is_training:False})\n",
    "            writer_train.add_summary(summary_train,epoch*size_multiple)\n",
    "            \n",
    "            print(\"Epoch:\",epoch)\n",
    "            print(\"test loss : %.4f\" % loss_test , \"test accuracy : %.4f\" % accuracy_test)\n",
    "            print(\"train loss: %.4f\" % loss_train, \"train accuracy: %.4f\" % accuracy_train)\n",
    "            print(\"elapsed time: %.0f\" % (time()-start_running), \"lr: %.1e\" % lr_)\n",
    "            print(\"Time to log:\",time()-start_time)\n",
    "        if epoch%50==0:\n",
    "            saver.save(sess,savedir+\"/model.ckpt\")\n",
    "    saver.save(sess,savedir+\"/model_final.ckpt\")\n",
    "    train_accuracy = np.mean(sess.run(pred, feed_dict={X:X_train, y:y_train,is_training:False})==y_train)\n",
    "    test_accuracy = np.mean(sess.run(pred, feed_dict={X:X_test, y:y_test,is_training:False})==y_test)\n",
    "    print(\"Test accuracy :\", test_accuracy)\n",
    "    print(\"Train accuracy:\", train_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
